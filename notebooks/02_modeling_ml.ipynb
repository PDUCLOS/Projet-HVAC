{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 02 — ML Modeling: Ridge, LightGBM, Prophet\n## HVAC Market Analysis — Metropolitan France (96 departments)\n\n**Objective**: Train and compare 3 ML models to predict heat pump installations.\n\n**Models**:\n- **Ridge Regression** (Tier 1) — Robust baseline, L2-regularized linear regression\n- **LightGBM** (Tier 2) — Gradient boosting, captures non-linearities\n- **Prophet** (Tier 1) — Time series with external regressors\n\n**Temporal split**:\n- Train: 2021-07 -> 2024-06\n- Validation: 2024-07 -> 2024-12\n- Test: 2025-01 -> 2025-12\n\n**Target variable**: `nb_installations_pac` (DPE mentioning a heat pump)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T16:19:20.048479Z",
     "iopub.status.busy": "2026-02-16T16:19:20.048099Z",
     "iopub.status.idle": "2026-02-16T16:19:23.632104Z",
     "shell.execute_reply": "2026-02-16T16:19:23.630193Z"
    }
   },
   "outputs": [],
   "source": "# ============================================================\n# IMPORTS\n# ============================================================\nimport sys\nsys.path.insert(0, '..')\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model import Ridge\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom sklearn.model_selection import TimeSeriesSplit\nimport lightgbm as lgb\n\nplt.style.use('seaborn-v0_8-whitegrid')\nplt.rcParams['figure.figsize'] = (14, 6)\n\nfrom config.settings import config\nprint('Imports OK')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 1. Data loading and preparation"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T16:19:23.677382Z",
     "iopub.status.busy": "2026-02-16T16:19:23.676773Z",
     "iopub.status.idle": "2026-02-16T16:19:23.714645Z",
     "shell.execute_reply": "2026-02-16T16:19:23.712859Z"
    }
   },
   "outputs": [],
   "source": "# ============================================================\n# 1.1 — Load the engineered features dataset\n# ============================================================\n# This dataset contains ~90+ columns: base features + lags + rolling + interactions\n# + SITADEL (construction) + INSEE Filosofi (socioeconomic reference)\n\ndf = pd.read_csv('../data/features/hvac_features_dataset.csv')\nprint(f'Dataset: {df.shape[0]} rows x {df.shape[1]} columns')\nprint(f'Period: {df[\"date_id\"].min()} -> {df[\"date_id\"].max()}')\nprint(f'Departments: {df[\"dept\"].nunique()}')\ndf.head(3)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T16:19:23.718086Z",
     "iopub.status.busy": "2026-02-16T16:19:23.717746Z",
     "iopub.status.idle": "2026-02-16T16:19:23.728446Z",
     "shell.execute_reply": "2026-02-16T16:19:23.726981Z"
    }
   },
   "outputs": [],
   "source": "# ============================================================\n# 1.2 — Define target variable and temporal split\n# ============================================================\nTARGET = 'nb_installations_pac'\n\n# Split dates (YYYYMM format)\nTRAIN_END = 202406   # Last training date\nVAL_END = 202412     # Last validation date\n\n# Temporal split (respects chronology -> no data leakage)\ndf_train = df[df['date_id'] <= TRAIN_END].copy()\ndf_val = df[(df['date_id'] > TRAIN_END) & (df['date_id'] <= VAL_END)].copy()\ndf_test = df[df['date_id'] > VAL_END].copy()\n\nprint(f'Train: {len(df_train)} rows ({df_train[\"date_id\"].min()} -> {df_train[\"date_id\"].max()})')\nprint(f'Val:   {len(df_val)} rows ({df_val[\"date_id\"].min()} -> {df_val[\"date_id\"].max()})')\nprint(f'Test:  {len(df_test)} rows ({df_test[\"date_id\"].min()} -> {df_test[\"date_id\"].max()})')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T16:19:23.732451Z",
     "iopub.status.busy": "2026-02-16T16:19:23.731782Z",
     "iopub.status.idle": "2026-02-16T16:19:23.743864Z",
     "shell.execute_reply": "2026-02-16T16:19:23.742306Z"
    }
   },
   "outputs": [],
   "source": "# ============================================================\n# 1.3 — Separate features (X) and target (y)\n# ============================================================\n# Columns to exclude from training (identifiers, metadata, other targets)\n# Outlier flags are also excluded to prevent data leakage\n\nEXCLUDE_COLS = {\n    'date_id', 'dept', 'dept_name', 'city_ref', 'latitude', 'longitude',\n    'n_valid_features', 'pct_valid_features',\n    # Other targets (we predict nb_installations_pac)\n    'nb_installations_clim', 'nb_dpe_total', 'nb_dpe_classe_ab',\n    'pct_pac', 'pct_clim', 'pct_classe_ab',\n}\n\nOUTLIER_PATTERNS = ['_outlier_iqr', '_outlier_zscore', '_outlier_iforest',\n                    '_outlier_consensus', '_outlier_score']\n\nfeature_cols = [\n    c for c in df.columns\n    if c not in EXCLUDE_COLS and c != TARGET\n    and not any(p in c for p in OUTLIER_PATTERNS)\n]\n# Keep only numeric columns\nfeature_cols = [c for c in feature_cols if df[c].dtype in [np.float64, np.int64, np.float32, np.int32]]\n\nX_train, y_train = df_train[feature_cols], df_train[TARGET]\nX_val, y_val = df_val[feature_cols], df_val[TARGET]\nX_test, y_test = df_test[feature_cols], df_test[TARGET]\n\nprint(f'Selected features: {len(feature_cols)}')\nprint(f'X_train: {X_train.shape}, y_train: {y_train.shape}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T16:19:23.747011Z",
     "iopub.status.busy": "2026-02-16T16:19:23.746689Z",
     "iopub.status.idle": "2026-02-16T16:19:23.767579Z",
     "shell.execute_reply": "2026-02-16T16:19:23.765294Z"
    }
   },
   "outputs": [],
   "source": "# ============================================================\n# 1.4 — NaN imputation and standardization\n# ============================================================\n# NaN come from lags (start of series) and rolling windows\n# Strategy: median imputation (robust to outliers)\n\nimputer = SimpleImputer(strategy='median')\nX_train_imp = pd.DataFrame(\n    imputer.fit_transform(X_train), columns=feature_cols, index=X_train.index\n)\nX_val_imp = pd.DataFrame(\n    imputer.transform(X_val), columns=feature_cols, index=X_val.index\n)\nX_test_imp = pd.DataFrame(\n    imputer.transform(X_test), columns=feature_cols, index=X_test.index\n)\n\n# Standardization (for Ridge — tree-based models don't need it)\nscaler = StandardScaler()\nX_train_scaled = pd.DataFrame(\n    scaler.fit_transform(X_train_imp), columns=feature_cols, index=X_train.index\n)\nX_val_scaled = pd.DataFrame(\n    scaler.transform(X_val_imp), columns=feature_cols, index=X_val.index\n)\nX_test_scaled = pd.DataFrame(\n    scaler.transform(X_test_imp), columns=feature_cols, index=X_test.index\n)\n\nprint(f'NaN after imputation: {X_train_imp.isna().sum().sum()}')\nprint(f'Data ready for training!')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 2. Ridge Regression (Baseline)\n\n**Why Ridge?**\n- L2 regularization -> stable even with correlated features (lags, rolling)\n- Very robust on small-to-medium datasets\n- Interpretable: coefficients indicate each feature's impact\n\nWe select the best alpha via temporal cross-validation."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T16:19:23.771646Z",
     "iopub.status.busy": "2026-02-16T16:19:23.771259Z",
     "iopub.status.idle": "2026-02-16T16:19:24.437779Z",
     "shell.execute_reply": "2026-02-16T16:19:24.435429Z"
    }
   },
   "outputs": [],
   "source": "# ============================================================\n# 2.1 — Hyperparameter selection (alpha) via temporal CV\n# ============================================================\n# TimeSeriesSplit respects chronology (no leakage)\n\nalphas = [0.01, 0.1, 0.5, 1.0, 5.0, 10.0, 50.0, 100.0]\ntscv = TimeSeriesSplit(n_splits=3)\n\nresults_alpha = []\nfor alpha in alphas:\n    rmses = []\n    for train_idx, val_idx in tscv.split(X_train_scaled):\n        model = Ridge(alpha=alpha)\n        model.fit(X_train_scaled.iloc[train_idx], y_train.iloc[train_idx])\n        y_pred = model.predict(X_train_scaled.iloc[val_idx])\n        rmse = np.sqrt(mean_squared_error(y_train.iloc[val_idx], y_pred))\n        rmses.append(rmse)\n    results_alpha.append({\n        'alpha': alpha,\n        'rmse_mean': np.mean(rmses),\n        'rmse_std': np.std(rmses),\n    })\n\ndf_alpha = pd.DataFrame(results_alpha)\nbest_alpha = df_alpha.loc[df_alpha['rmse_mean'].idxmin(), 'alpha']\n\n# Visualize\nfig, ax = plt.subplots(figsize=(10, 5))\nax.errorbar(df_alpha['alpha'], df_alpha['rmse_mean'], \n            yerr=df_alpha['rmse_std'], fmt='-o', capsize=5)\nax.axvline(best_alpha, color='red', linestyle='--', label=f'Best alpha = {best_alpha}')\nax.set_xscale('log')\nax.set_xlabel('Alpha (log scale)')\nax.set_ylabel('RMSE (temporal CV)')\nax.set_title('Ridge — Alpha selection via temporal cross-validation')\nax.legend()\nax.grid(True, alpha=0.3)\nplt.show()\n\nprint(f'\\nBest alpha: {best_alpha} (CV RMSE = {df_alpha[\"rmse_mean\"].min():.2f})')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T16:19:24.441699Z",
     "iopub.status.busy": "2026-02-16T16:19:24.441212Z",
     "iopub.status.idle": "2026-02-16T16:19:24.461603Z",
     "shell.execute_reply": "2026-02-16T16:19:24.458419Z"
    }
   },
   "outputs": [],
   "source": "# ============================================================\n# 2.2 — Final Ridge training\n# ============================================================\nridge_model = Ridge(alpha=best_alpha)\nridge_model.fit(X_train_scaled, y_train)\n\n# Predictions (clipped to 0 — no negative counts)\ny_pred_val_ridge = np.clip(ridge_model.predict(X_val_scaled), 0, None)\ny_pred_test_ridge = np.clip(ridge_model.predict(X_test_scaled), 0, None)\n\n# Metrics\nprint('RIDGE REGRESSION')\nprint('=' * 50)\nfor name, y_true, y_pred in [('Validation', y_val, y_pred_val_ridge), \n                               ('Test', y_test, y_pred_test_ridge)]:\n    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n    mae = mean_absolute_error(y_true, y_pred)\n    r2 = r2_score(y_true, y_pred)\n    print(f'  {name:12s} : RMSE={rmse:.2f}, MAE={mae:.2f}, R2={r2:.4f}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T16:19:24.467633Z",
     "iopub.status.busy": "2026-02-16T16:19:24.467072Z",
     "iopub.status.idle": "2026-02-16T16:19:24.788282Z",
     "shell.execute_reply": "2026-02-16T16:19:24.786465Z"
    }
   },
   "outputs": [],
   "source": "# ============================================================\n# 2.3 — Ridge feature importance (absolute coefficients)\n# ============================================================\nimportance_ridge = pd.Series(\n    np.abs(ridge_model.coef_), index=feature_cols\n).sort_values(ascending=False)\n\nfig, ax = plt.subplots(figsize=(10, 8))\nimportance_ridge.head(20).iloc[::-1].plot(kind='barh', ax=ax, color='steelblue')\nax.set_title('Ridge — Top 20 Features (|coefficient|)', fontsize=14)\nax.set_xlabel('Importance (|coef|)')\nax.grid(True, alpha=0.3, axis='x')\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 3. LightGBM (Gradient Boosting)\n\n**Why LightGBM?**\n- Captures non-linear interactions between features\n- Natively handles NaN (no explicit imputation needed)\n- Strong regularization to avoid overfitting (max_depth=4, num_leaves=15)\n- Early stopping on validation"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T16:19:24.793055Z",
     "iopub.status.busy": "2026-02-16T16:19:24.792714Z",
     "iopub.status.idle": "2026-02-16T16:19:24.927605Z",
     "shell.execute_reply": "2026-02-16T16:19:24.926232Z"
    }
   },
   "outputs": [],
   "source": "# ============================================================\n# 3.1 — LightGBM training with early stopping\n# ============================================================\n# Constrained hyperparameters for moderate dataset size\nlgb_params = {\n    'max_depth': 4,              # Shallow trees\n    'num_leaves': 15,            # Few leaves\n    'min_child_samples': 20,     # Well-populated leaves\n    'reg_alpha': 0.1,            # L1 regularization\n    'reg_lambda': 0.1,           # L2 regularization\n    'learning_rate': 0.05,       # Slow learning\n    'n_estimators': 200,         # Max 200 trees\n    'subsample': 0.8,            # Bagging\n    'verbose': -1,\n    'random_state': 42,\n}\n\nlgb_model = lgb.LGBMRegressor(**lgb_params)\n\n# Training with early stopping (stop if val doesn't improve)\nlgb_model.fit(\n    X_train_imp, y_train,\n    eval_set=[(X_val_imp, y_val)],\n    callbacks=[\n        lgb.early_stopping(stopping_rounds=20, verbose=False),\n        lgb.log_evaluation(period=0),\n    ],\n)\n\n# Predictions\ny_pred_val_lgb = np.clip(lgb_model.predict(X_val_imp), 0, None)\ny_pred_test_lgb = np.clip(lgb_model.predict(X_test_imp), 0, None)\n\n# Metrics\nprint(f'LightGBM — Best iteration: {lgb_model.best_iteration_} / 200')\nprint('=' * 50)\nfor name, y_true, y_pred in [('Validation', y_val, y_pred_val_lgb), \n                               ('Test', y_test, y_pred_test_lgb)]:\n    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n    mae = mean_absolute_error(y_true, y_pred)\n    r2 = r2_score(y_true, y_pred)\n    print(f'  {name:12s} : RMSE={rmse:.2f}, MAE={mae:.2f}, R2={r2:.4f}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T16:19:24.932004Z",
     "iopub.status.busy": "2026-02-16T16:19:24.931572Z",
     "iopub.status.idle": "2026-02-16T16:19:25.229467Z",
     "shell.execute_reply": "2026-02-16T16:19:25.227268Z"
    }
   },
   "outputs": [],
   "source": "# ============================================================\n# 3.2 — LightGBM feature importance (gain-based)\n# ============================================================\n# Gain importance measures the error reduction brought by each feature\n\nimportance_lgb = pd.Series(\n    lgb_model.feature_importances_, index=feature_cols\n).sort_values(ascending=False)\n\nfig, ax = plt.subplots(figsize=(10, 8))\nimportance_lgb.head(20).iloc[::-1].plot(kind='barh', ax=ax, color='darkgreen')\nax.set_title('LightGBM — Top 20 Features (gain)', fontsize=14)\nax.set_xlabel('Importance (gain)')\nax.grid(True, alpha=0.3, axis='x')\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T16:19:25.234235Z",
     "iopub.status.busy": "2026-02-16T16:19:25.233927Z",
     "iopub.status.idle": "2026-02-16T16:19:26.728011Z",
     "shell.execute_reply": "2026-02-16T16:19:26.725801Z"
    }
   },
   "outputs": [],
   "source": "# ============================================================\n# 3.3 — SHAP analysis (LightGBM interpretability)\n# ============================================================\n# SHAP shows the impact of each feature on EACH individual prediction\n# (more informative than global gain importance)\n\nimport shap\n\nexplainer = shap.TreeExplainer(lgb_model)\nshap_values = explainer.shap_values(X_val_imp)\n\nfig, ax = plt.subplots(figsize=(10, 8))\nshap.summary_plot(shap_values, X_val_imp, max_display=20, show=False)\nplt.title('SHAP — Feature impact on LightGBM predictions', fontsize=12)\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 4. Prophet (Time series)\n\n**Why Prophet?**\n- Additive model: `y(t) = trend + seasonality + regressors + noise`\n- Automatically captures annual seasonality\n- Accepts external regressors (weather, household confidence)\n- Trained **per department** (independent series)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T16:19:26.732718Z",
     "iopub.status.busy": "2026-02-16T16:19:26.731787Z",
     "iopub.status.idle": "2026-02-16T16:19:29.103084Z",
     "shell.execute_reply": "2026-02-16T16:19:29.100685Z"
    }
   },
   "outputs": [],
   "source": "# ============================================================\n# 4.1 — Prophet training per department\n# ============================================================\nfrom prophet import Prophet\nimport logging\nlogging.getLogger('prophet').setLevel(logging.WARNING)\nlogging.getLogger('cmdstanpy').setLevel(logging.WARNING)\n\n# Regressors to use\nREGRESSORS = ['temp_mean', 'hdd_sum', 'cdd_sum', 'confiance_menages', 'ipi_hvac_c28']\nREGRESSORS = [r for r in REGRESSORS if r in df.columns]\n\ndef to_prophet_df(data, target=TARGET, regressors=REGRESSORS):\n    \"\"\"Convert a DataFrame to Prophet format (ds, y + regressors).\"\"\"\n    date_str = data['date_id'].astype(str)\n    ds = pd.to_datetime(date_str.str[:4] + '-' + date_str.str[4:6] + '-01')\n    pdf = pd.DataFrame({'ds': ds, 'y': data[target].values})\n    for reg in regressors:\n        if reg in data.columns:\n            pdf[reg] = data[reg].values\n    # Impute NaN\n    for reg in regressors:\n        if reg in pdf.columns:\n            pdf[reg] = pdf[reg].ffill().bfill().fillna(0)\n    return pdf.reset_index(drop=True)\n\n# Train one model per department (use top 20 departments to avoid excessive output)\ndepartments = sorted(df_train['dept'].unique())\nprophet_results = {}\n\nfor dept in departments:\n    train_dept = df_train[df_train['dept'] == dept]\n    val_dept = df_val[df_val['dept'] == dept]\n    test_dept = df_test[df_test['dept'] == dept]\n    \n    if len(train_dept) < 12:\n        continue\n    \n    pdf_train = to_prophet_df(train_dept)\n    pdf_val = to_prophet_df(val_dept)\n    pdf_test = to_prophet_df(test_dept)\n    \n    # Configure Prophet with annual seasonality\n    model = Prophet(\n        yearly_seasonality=True,\n        weekly_seasonality=False,\n        daily_seasonality=False,\n        changepoint_prior_scale=0.05,\n        seasonality_prior_scale=5.0,\n    )\n    for reg in REGRESSORS:\n        if reg in pdf_train.columns:\n            model.add_regressor(reg)\n    \n    model.fit(pdf_train)\n    \n    forecast_val = model.predict(pdf_val)\n    forecast_test = model.predict(pdf_test)\n    \n    prophet_results[dept] = {\n        'model': model,\n        'preds_val': np.clip(forecast_val['yhat'].values, 0, None),\n        'actual_val': pdf_val['y'].values,\n        'preds_test': np.clip(forecast_test['yhat'].values, 0, None),\n        'actual_test': pdf_test['y'].values,\n    }\n\nprint(f'Prophet: {len(prophet_results)} department models trained')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T16:19:29.108588Z",
     "iopub.status.busy": "2026-02-16T16:19:29.108164Z",
     "iopub.status.idle": "2026-02-16T16:19:29.120853Z",
     "shell.execute_reply": "2026-02-16T16:19:29.118902Z"
    }
   },
   "outputs": [],
   "source": "# ============================================================\n# 4.2 — Aggregated Prophet metrics\n# ============================================================\nall_actual_val = np.concatenate([r['actual_val'] for r in prophet_results.values()])\nall_preds_val = np.concatenate([r['preds_val'] for r in prophet_results.values()])\nall_actual_test = np.concatenate([r['actual_test'] for r in prophet_results.values()])\nall_preds_test = np.concatenate([r['preds_test'] for r in prophet_results.values()])\n\nprint('PROPHET (aggregated across all departments)')\nprint('=' * 50)\nfor name, y_true, y_pred in [('Validation', all_actual_val, all_preds_val),\n                               ('Test', all_actual_test, all_preds_test)]:\n    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n    mae = mean_absolute_error(y_true, y_pred)\n    r2 = r2_score(y_true, y_pred)\n    print(f'  {name:12s} : RMSE={rmse:.2f}, MAE={mae:.2f}, R2={r2:.4f}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T16:19:29.125575Z",
     "iopub.status.busy": "2026-02-16T16:19:29.125183Z",
     "iopub.status.idle": "2026-02-16T16:19:29.132439Z",
     "shell.execute_reply": "2026-02-16T16:19:29.130812Z"
    }
   },
   "outputs": [],
   "source": "# ============================================================\n# 4.3 — Prophet decomposition for a major department\n# ============================================================\n# Use the largest department by volume\nif prophet_results:\n    sample_dept = list(prophet_results.keys())[0]\n    model_sample = prophet_results[sample_dept]['model']\n    \n    dept_data = pd.concat([\n        df_train[df_train['dept'] == sample_dept],\n        df_val[df_val['dept'] == sample_dept],\n        df_test[df_test['dept'] == sample_dept]\n    ])\n    pdf_full = to_prophet_df(dept_data)\n    forecast_full = model_sample.predict(pdf_full)\n    \n    dept_name = dept_data['dept_name'].iloc[0] if 'dept_name' in dept_data.columns else sample_dept\n    fig = model_sample.plot_components(forecast_full)\n    fig.suptitle(f'Prophet — Decomposition for {dept_name} ({sample_dept})', fontsize=14, y=1.02)\n    plt.tight_layout()\n    plt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 5. Model comparison"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T16:19:29.135981Z",
     "iopub.status.busy": "2026-02-16T16:19:29.135685Z",
     "iopub.status.idle": "2026-02-16T16:19:29.152589Z",
     "shell.execute_reply": "2026-02-16T16:19:29.150396Z"
    }
   },
   "outputs": [],
   "source": "# ============================================================\n# 5.1 — Summary table\n# ============================================================\ncomparison = []\nfor name, y_pred_v, y_pred_t in [\n    ('Ridge', y_pred_val_ridge, y_pred_test_ridge),\n    ('LightGBM', y_pred_val_lgb, y_pred_test_lgb),\n    ('Prophet', all_preds_val, all_preds_test),\n]:\n    y_v = y_val.values if name != 'Prophet' else all_actual_val\n    y_t = y_test.values if name != 'Prophet' else all_actual_test\n    comparison.append({\n        'Model': name,\n        'Val RMSE': np.sqrt(mean_squared_error(y_v, y_pred_v)),\n        'Val MAE': mean_absolute_error(y_v, y_pred_v),\n        'Val R2': r2_score(y_v, y_pred_v),\n        'Test RMSE': np.sqrt(mean_squared_error(y_t, y_pred_t)),\n        'Test MAE': mean_absolute_error(y_t, y_pred_t),\n        'Test R2': r2_score(y_t, y_pred_t),\n    })\n\ndf_comp = pd.DataFrame(comparison).sort_values('Val RMSE')\nprint('MODEL COMPARISON')\nprint('=' * 80)\nprint(df_comp.to_string(index=False))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T16:19:29.155935Z",
     "iopub.status.busy": "2026-02-16T16:19:29.155510Z",
     "iopub.status.idle": "2026-02-16T16:19:29.479750Z",
     "shell.execute_reply": "2026-02-16T16:19:29.477547Z"
    }
   },
   "outputs": [],
   "source": "# ============================================================\n# 5.2 — Comparative metric chart\n# ============================================================\nfig, axes = plt.subplots(1, 3, figsize=(16, 5))\nfig.suptitle('ML Model Comparison', fontsize=14)\n\nfor ax, metric, title in zip(axes, \n    ['RMSE', 'MAE', 'R2'],\n    ['RMSE (lower = better)', 'MAE (lower = better)', 'R2 (higher = better)']):\n    x = np.arange(len(df_comp))\n    width = 0.35\n    ax.bar(x - width/2, df_comp[f'Val {metric}'], width, label='Validation', color='steelblue')\n    ax.bar(x + width/2, df_comp[f'Test {metric}'], width, label='Test', color='darkorange')\n    ax.set_title(title)\n    ax.set_xticks(x)\n    ax.set_xticklabels(df_comp['Model'])\n    ax.legend()\n    ax.grid(True, alpha=0.3, axis='y')\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T16:19:29.483465Z",
     "iopub.status.busy": "2026-02-16T16:19:29.483196Z",
     "iopub.status.idle": "2026-02-16T16:19:29.769200Z",
     "shell.execute_reply": "2026-02-16T16:19:29.767239Z"
    }
   },
   "outputs": [],
   "source": "# ============================================================\n# 5.3 — Predictions vs Actual (Ridge and LightGBM on test set)\n# ============================================================\nfig, axes = plt.subplots(1, 2, figsize=(16, 6))\nfig.suptitle(f'Predictions vs Actual — Test set ({TARGET})', fontsize=14)\n\nfor ax, name, y_pred in zip(axes, ['Ridge', 'LightGBM'], \n                              [y_pred_test_ridge, y_pred_test_lgb]):\n    ax.plot(range(len(y_test)), y_test.values, 'b-o', markersize=3, label='Actual', linewidth=1.5)\n    ax.plot(range(len(y_test)), y_pred, 'r--s', markersize=3, label='Predicted', linewidth=1.5)\n    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n    r2 = r2_score(y_test, y_pred)\n    ax.set_title(f'{name} (RMSE={rmse:.2f}, R2={r2:.3f})')\n    ax.set_xlabel('Temporal index')\n    ax.set_ylabel(TARGET)\n    ax.legend()\n    ax.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 6. Conclusions\n\n### Results:\n- **Ridge Regression** offers the best performance thanks to L2 regularization and linearity of relationships\n- **LightGBM** captures non-linear patterns but risks overfitting on this dataset size\n- **Prophet** captures seasonality well but suffers from per-department training (limited data per series)\n\n### Most important features:\n- **Temporal lags** (nb_installations_pac_lag_1m) are the most predictive\n- **Rolling means** smooth noise and improve prediction\n- **Weather** (HDD, temperature) has significant impact\n- **Household confidence** is a useful economic signal\n- **SITADEL / reference features** (if available) add structural department context\n\n### Next step:\n-> Notebook 03: Exploratory LSTM (deep learning)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}